{"nbformat": 4, "nbformat_minor": 1, "cells": [{"metadata": {}, "source": ["## Basic binary classification with kNN[\u00b6](#Basic-binary-classification-with-kNN)\r\n\r\nThis section gets us started with displaying basic binary classification using 2D data. We first show how to display training versus testing data using [various marker styles](https://plot.ly/python/marker-style/), then demonstrate how to evaluate our classifier's performance on the **test split** using a continuous color gradient to indicate the model's predicted score.\r\n\r\nWe will use [Scikit-learn](https://scikit-learn.org/) for training our model and for loading and splitting data. Scikit-learn is a popular Machine Learning (ML) library that offers various tools for creating and training ML algorithms, feature engineering, data cleaning, and evaluating and testing models. It was designed to be accessible, and to work seamlessly with popular libraries like NumPy and Pandas.\r\n\r\nWe will train a [k-Nearest Neighbors (kNN)](https://scikit-learn.org/stable/modules/neighbors.html) classifier. First, the model records the label of each training sample. Then, whenever we give it a new sample, it will look at the `k` closest samples from the training set to find the most common label, and assign it to our new sample."], "cell_type": "markdown"}, {"metadata": {}, "source": ["### Display training and test splits[\u00b6](#Display-training-and-test-splits)\r\n\r\nUsing Scikit-learn, we first generate synthetic data that form the shape of a moon. We then split it into a training and testing set. Finally, we display the ground truth labels using [a scatter plot](https://plotly.com/python/line-and-scatter/).\r\n\r\nIn the graph, we display all the negative labels as squares, and positive labels as circles. We differentiate the training and test set by adding a dot to the center of test data.\r\n\r\nIn this example, we will use [graph objects](/python/graph-objects/), Plotly's low-level API for building figures."], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\nimport plotly.graph_objects as go\nimport numpy as np\nfrom sklearn.datasets import make_moons\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Load and split data\nX, y = make_moons(noise=0.3, random_state=0)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y.astype(str), test_size=0.25, random_state=0)\n\ntrace_specs = [\n    [X_train, y_train, '0', 'Train', 'square'],\n    [X_train, y_train, '1', 'Train', 'circle'],\n    [X_test, y_test, '0', 'Test', 'square-dot'],\n    [X_test, y_test, '1', 'Test', 'circle-dot']\n]\n\nfig = go.Figure(data=[\n    go.Scatter(\n        x=X[y==label, 0], y=X[y==label, 1],\n        name=f'{split} Split, Label {label}',\n        mode='markers', marker_symbol=marker\n    )\n    for X, y, label, split, marker in trace_specs\n])\nfig.update_traces(\n    marker_size=12, marker_line_width=1.5,\n    marker_color=\"lightyellow\"\n)\nfig.show()\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["### Visualize predictions on test split with [`plotly.express`](https://plotly.com/python/plotly-express/)[\u00b6](#Visualize-predictions-on-test-split-with-plotly.express)"], "cell_type": "markdown"}, {"metadata": {}, "source": ["Now, we train the kNN model on the same training data displayed in the previous graph. Then, we predict the confidence score of the model for each of the data points in the test set. We will use shapes to denote the true labels, and the color will indicate the confidence of the model for assign that score.\r\n\r\nIn this example, we will use [Plotly Express](/python/plotly-express/), Plotly's high-level API for building figures. Notice that `px.scatter` only require 1 function call to plot both negative and positive labels, and can additionally set a continuous color scale based on the `y_score` output by our kNN model."], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\nimport plotly.express as px\nimport numpy as np\nfrom sklearn.datasets import make_moons\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Load and split data\nX, y = make_moons(noise=0.3, random_state=0)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y.astype(str), test_size=0.25, random_state=0)\n\n# Fit the model on training data, predict on test data\nclf = KNeighborsClassifier(15)\nclf.fit(X_train, y_train)\ny_score = clf.predict_proba(X_test)[:, 1]\n\nfig = px.scatter(\n    X_test, x=0, y=1,\n    color=y_score, color_continuous_scale='RdBu',\n    symbol=y_test, symbol_map={'0': 'square-dot', '1': 'circle-dot'},\n    labels={'symbol': 'label', 'color': 'score of <br>first class'}\n)\nfig.update_traces(marker_size=12, marker_line_width=1.5)\nfig.update_layout(legend_orientation='h')\nfig.show()\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["## Probability Estimates with `go.Contour`[\u00b6](#Probability-Estimates-with-go.Contour)\r\n\r\nJust like the previous example, we will first train our kNN model on the training set.\r\n\r\nInstead of predicting the conference for the test set, we can predict the confidence map for the entire area that wraps around the dimensions of our dataset. To do this, we use [`np.meshgrid`](https://numpy.org/doc/stable/reference/generated/numpy.meshgrid.html) to create a grid, where the distance between each point is denoted by the `mesh_size` variable.\r\n\r\nThen, for each of those points, we will use our model to give a confidence score, and plot it with a [contour plot](https://plotly.com/python/contour-plots/).\r\n\r\nIn this example, we will use [graph objects](/python/graph-objects/), Plotly's low-level API for building figures."], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\nimport plotly.graph_objects as go\nimport numpy as np\nfrom sklearn.datasets import make_moons\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n\nmesh_size = .02\nmargin = 0.25\n\n# Load and split data\nX, y = make_moons(noise=0.3, random_state=0)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y.astype(str), test_size=0.25, random_state=0)\n\n# Create a mesh grid on which we will run our model\nx_min, x_max = X[:, 0].min() - margin, X[:, 0].max() + margin\ny_min, y_max = X[:, 1].min() - margin, X[:, 1].max() + margin\nxrange = np.arange(x_min, x_max, mesh_size)\nyrange = np.arange(y_min, y_max, mesh_size)\nxx, yy = np.meshgrid(xrange, yrange)\n\n# Create classifier, run predictions on grid\nclf = KNeighborsClassifier(15, weights='uniform')\nclf.fit(X, y)\nZ = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\nZ = Z.reshape(xx.shape)\n\n\n# Plot the figure\nfig = go.Figure(data=[\n    go.Contour(\n        x=xrange,\n        y=yrange,\n        z=Z,\n        colorscale='RdBu'\n    )\n])\nfig.show()\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["Now, let's try to combine our `go.Contour` plot with the first scatter plot of our data points, so that we can visually compare the confidence of our model with the true labels."], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\nimport plotly.graph_objects as go\nimport numpy as np\nfrom sklearn.datasets import make_moons\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n\nmesh_size = .02\nmargin = 0.25\n\n# Load and split data\nX, y = make_moons(noise=0.3, random_state=0)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y.astype(str), test_size=0.25, random_state=0)\n\n# Create a mesh grid on which we will run our model\nx_min, x_max = X[:, 0].min() - margin, X[:, 0].max() + margin\ny_min, y_max = X[:, 1].min() - margin, X[:, 1].max() + margin\nxrange = np.arange(x_min, x_max, mesh_size)\nyrange = np.arange(y_min, y_max, mesh_size)\nxx, yy = np.meshgrid(xrange, yrange)\n\n# Create classifier, run predictions on grid\nclf = KNeighborsClassifier(15, weights='uniform')\nclf.fit(X, y)\nZ = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\nZ = Z.reshape(xx.shape)\n\ntrace_specs = [\n    [X_train, y_train, '0', 'Train', 'square'],\n    [X_train, y_train, '1', 'Train', 'circle'],\n    [X_test, y_test, '0', 'Test', 'square-dot'],\n    [X_test, y_test, '1', 'Test', 'circle-dot']\n]\n\nfig = go.Figure(data=[\n    go.Scatter(\n        x=X[y==label, 0], y=X[y==label, 1],\n        name=f'{split} Split, Label {label}',\n        mode='markers', marker_symbol=marker\n    )\n    for X, y, label, split, marker in trace_specs\n])\nfig.update_traces(\n    marker_size=12, marker_line_width=1.5,\n    marker_color=\"lightyellow\"\n)\n\nfig.add_trace(\n    go.Contour(\n        x=xrange,\n        y=yrange,\n        z=Z,\n        showscale=False,\n        colorscale='RdBu',\n        opacity=0.4,\n        name='Score',\n        hoverinfo='skip'\n    )\n)\nfig.show()\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["## Multi-class prediction confidence with [`go.Heatmap`](https://plotly.com/python/heatmaps/)[\u00b6](#Multi-class-prediction-confidence-with-go.Heatmap)\r\n\r\nIt is also possible to visualize the prediction confidence of the model using [heatmaps](https://plotly.com/python/heatmaps/). In this example, you can see how to compute how confident the model is about its prediction at every point in the 2D grid. Here, we define the confidence as the difference between the highest score and the score of the other classes summed, at a certain point.\r\n\r\nIn this example, we will use [Plotly Express](/python/plotly-express/), Plotly's high-level API for building figures."], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\n\nmesh_size = .02\nmargin = 1\n\n# We will use the iris data, which is included in px\ndf = px.data.iris()\ndf_train, df_test = train_test_split(df, test_size=0.25, random_state=0)\nX_train = df_train[['sepal_length', 'sepal_width']]\ny_train = df_train.species_id\n\n# Create a mesh grid on which we will run our model\nl_min, l_max = df.sepal_length.min() - margin, df.sepal_length.max() + margin\nw_min, w_max = df.sepal_width.min() - margin, df.sepal_width.max() + margin\nlrange = np.arange(l_min, l_max, mesh_size)\nwrange = np.arange(w_min, w_max, mesh_size)\nll, ww = np.meshgrid(lrange, wrange)\n\n# Create classifier, run predictions on grid\nclf = KNeighborsClassifier(15, weights='distance')\nclf.fit(X_train, y_train)\nZ = clf.predict(np.c_[ll.ravel(), ww.ravel()])\nZ = Z.reshape(ll.shape)\nproba = clf.predict_proba(np.c_[ll.ravel(), ww.ravel()])\nproba = proba.reshape(ll.shape + (3,))\n\n# Compute the confidence, which is the difference\ndiff = proba.max(axis=-1) - (proba.sum(axis=-1) - proba.max(axis=-1))\n\nfig = px.scatter(\n    df_test, x='sepal_length', y='sepal_width',\n    symbol='species',\n    symbol_map={\n        'setosa': 'square-dot',\n        'versicolor': 'circle-dot',\n        'virginica': 'diamond-dot'},\n)\nfig.update_traces(\n    marker_size=12, marker_line_width=1.5,\n    marker_color=\"lightyellow\"\n)\nfig.add_trace(\n    go.Heatmap(\n        x=lrange,\n        y=wrange,\n        z=diff,\n        opacity=0.25,\n        customdata=proba,\n        colorscale='RdBu',\n        hovertemplate=(\n            'sepal length: %{x} <br>'\n            'sepal width: %{y} <br>'\n            'p(setosa): %{customdata[0]:.3f}<br>'\n            'p(versicolor): %{customdata[1]:.3f}<br>'\n            'p(virginica): %{customdata[2]:.3f}<extra></extra>'\n        )\n    )\n)\nfig.update_layout(\n    legend_orientation='h',\n    title='Prediction Confidence on Test Split'\n)\nfig.show()\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["### Reference[\u00b6](#Reference)\r\n\r\nLearn more about `px`, `go.Contour`, and `go.Heatmap` here:\r\n\r\n*  [https://plot.ly/python/plotly-express/](https://plot.ly/python/plotly-express/)\r\n*  [https://plot.ly/python/heatmaps/](https://plot.ly/python/heatmaps/)\r\n*  [https://plot.ly/python/contour-plots/](https://plot.ly/python/contour-plots/)\r\n\r\nThis tutorial was inspired by amazing examples from the official scikit-learn docs:\r\n\r\n*  [https://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html](https://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html)\r\n*  [https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html)\r\n*  [https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html)"], "cell_type": "markdown"}, {"metadata": {}, "source": ["### What About Dash?[\u00b6](#What-About-Dash?)\r\n\r\n[Dash](https://dash.plot.ly/) is an open-source framework for building analytical applications, with no Javascript required, and it is tightly integrated with the Plotly graphing library.\r\n\r\nLearn about how to install Dash at [https://dash.plot.ly/installation](https://dash.plot.ly/installation).\r\n\r\nEverywhere in this page that you see `fig.show()`, you can display the same figure in a Dash application by passing it to the `figure` argument of the [`Graph` component](https://dash.plot.ly/dash-core-components/graph) from the built-in `dash_core_components` package like this:\r\n\r\n``` \r\nimport plotly.graph_objects as go # or plotly.express as px\nfig = go.Figure() # or any Plotly Express function e.g. px.bar(...)\n# fig.add_trace( ... )\n# fig.update_layout( ... )\n\nimport dash\nimport dash_core_components as dcc\nimport dash_html_components as html\n\napp = dash.Dash()\napp.layout = html.Div([\n    dcc.Graph(figure=fig)\n])\n\napp.run_server(debug=True, use_reloader=False)  # Turn off reloader if inside Jupyter\r\n```"], "cell_type": "markdown"}], "metadata": {}}